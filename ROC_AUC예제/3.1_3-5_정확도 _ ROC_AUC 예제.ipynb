{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\JSWonner\\\\Desktop\\\\python_p\\\\Classifier\\\\ROC_AUC예제'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 평가(Evaluation)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "학습 데이터로 분류 모델을 만들고, 이를 테스트 데이터에 넣어서 좋은 모델인지 성능을 평가하고자 한다.\n",
    "이 때 사용되는 분류 성능평가 지표들과 함수들에 대해 알아보자\n",
    "\n",
    "- 오차행렬\n",
    "- 정확도\n",
    "- 정밀도,재현율\n",
    "- 정밀도와 재현율의 (trade-off) 관계\n",
    "- F1 Score\n",
    "- ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 경고 메시지 무시\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 정확도(Accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "이진 분류 시 정확도는 그닥 좋은 평가 지표는 아니다. 예시를 들어서 살펴보면,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 타이타닉 데이터 - 성별로만 생존, 사망 예측하는 DummyClassifier 만들어서 학습 및 예측 정확도 구해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.zeros( (titanic_df.shape[0], 1) )\n",
    "\n",
    "print(len(pred))\n",
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 1)\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0]==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "# 성별로만 생존, 사망을 예측하는 클래스\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit 메소드는 아무것도 학습하지 않음.\n",
    "    def fit(self, X , y=None):\n",
    "        pass\n",
    "    \n",
    "    # 데이터프레임(X)의 성별(Sex)이 여자면(0) 생존(1), 남자(1)면 사망(0)으로 하는 pred를 반환함.\n",
    "    def predict(self, X):\n",
    "        # pred는 성별을 기준으로 생존(1), 사망(0)을 예측하는 것\n",
    "        pred = np.zeros( ( X.shape[0], 1 ))\n",
    "        for i in range (X.shape[0]) :\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('./titanic_train.csv')\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수들\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 타이타닉 데이터 로드 및 feature(X), target(y) 데이터 분리\n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "\n",
    "# 데이터 전처리\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "# train, test 데이터 분리 \n",
    "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                  test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDummyClassifier의 정확도는: 0.7877\n"
     ]
    }
   ],
   "source": [
    "# MyDummyClassifier 객체 생성\n",
    "myclf = MyDummyClassifier()\n",
    "\n",
    "# MyDummyClassifier 학습\n",
    "myclf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('MyDummyClassifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test , mypredictions)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> 여성이면 생존, 남성이면 사망이라는 단순한 모델로 예측해도 정확도가 79%가 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) mnist 예측 - 7이면 True, 다른 숫자는 False인 모델 만들어서 학습 및 예측 정확도 구해보기"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mnist 데이터 : 손글씨 0~9까지 적혀있는 데이터\n",
    "궁금증. 숫자 10개 중 1개만 7이므로, \"모두 7이 아니다\"라고 예측하면 정확도가 90%가 나오지 않을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits  # mnist 데이터셋 로드\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 데이터를 0으로 만드는 클래스\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    # 입력값으로 들어오는 X 데이터 셋의 크기만큼 모두 0값으로 만들어서 반환\n",
    "    def predict(self, X):\n",
    "        return np.zeros( (len(X), 1) , dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사이킷런의 내장 데이터 셋인 load_digits( )를 이용하여 MNIST 데이터 로딩\n",
    "digits = load_digits()\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist의 feature 데이터\n",
    "print(digits.data.shape)\n",
    "digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist의 target 데이터\n",
    "print(digits.target.shape)\n",
    "digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print(digits.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0] #문자가 가진 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data[0] #이미지 데이터를 1차원 배열로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7번이면 True이고 1로 변환, 7번이 아니면 False이고 0으로 변환.\n",
    "y = (digits.target == 7).astype(int)\n",
    "#타겟값을 변경\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1347,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# InteractiveShell : print 안 써도 쉘의 모든 결과를 출력해주는 라이브러리\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "print(X_train.shape)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(450,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기 : (450,) \n",
      "\n",
      "테스트 세트 레이블 0(7이 아닌 숫자)과 1(숫자 7)의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 불균형한 레이블 데이터 분포도 확인. \n",
    "print('레이블 테스트 세트 크기 :', y_test.shape, '\\n')\n",
    "\n",
    "print('테스트 세트 레이블 0(7이 아닌 숫자)과 1(숫자 7)의 분포도')\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 예측을 0으로 하여도 정확도는:0.900\n"
     ]
    }
   ],
   "source": [
    "# MyFakeClassifier(모든 숫자 예측을 0으로 하는 모델)로 학습 및 예측\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train , y_train)\n",
    "\n",
    "# 정확도 평가\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "\n",
    "fakepred.reshape(1,-1)\n",
    "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test , fakepred.reshape(-1))))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> 이진 분류 시 정확도는 그닥 좋은 평가 지표는 아니다. 이진분류 시 사용할 수 있는 다른 평가지표들을 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 오차 행렬(Confusion Matrix)과 정밀도(precision), 재현율(recall) 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오차 행렬(Confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 예측 결과 fakepred와 실제 결과 y_test의 Confusion Matrix출력\n",
    "confusion_matrix(y_test, fakepred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "정확도 : 예측 결과와 실제 값이 동일한 건수 / 전체 데이터 \n",
    "\t\t\t        = (TN + TP)  /  (TN + TP + FN + FP)\n",
    "\n",
    "여기서는 405/450 = 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정밀도(Precision)와 재현율(Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MyFakeClassifier의 예측 결과로 정밀도와 재현율 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도: 0.0\n",
      "재현율: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score\n",
    "\n",
    "print(\"정밀도:\", precision_score(y_test, fakepred)) #TP/ FP+TP\n",
    "print(\"재현율:\", recall_score(y_test, fakepred)) #TP/ FN+TP"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> 정밀도, 재현율이 0인 것을 보니, MyFakeClassifier가 이상한 모델임이 드러남"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오차행렬, 정확도, 정밀도, 재현율을 한꺼번에 계산하는 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix\n",
    "\n",
    "# confusion matrix, accuracy, precision, recall을 한꺼번에 계산하는 함수\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy , precision ,recall), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타이타닉 데이터에 로지스틱 회귀 모델로 이진 분류한 후에 오차행렬, 정확도, 정밀도, 재현율 구해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 타이타닉 데이터 로드\n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "\n",
    "# feature(X), target(y) 데이터 분리\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "\n",
    "# 데이터 전처리\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "# train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                    test_size=0.20, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로지스틱 회귀(분류 모델) 모델 정의\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "lr_clf.fit(X_train , y_train)\n",
    "\n",
    "# 예측\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test , pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 정밀도와 재현율의 (trade-off) 관계"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "먼저 결론부터 보면 :\n",
    "적절한 분류 임계값을 설정하면 원하는 정밀도, 재현율 각각의 값을 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict_proba 함수 : 분류 결정 예측 확률을 반환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.46175211, 0.53824789],\n",
       "       [0.87863924, 0.12136076],\n",
       "       [0.87717092, 0.12282908],\n",
       "       [0.88269294, 0.11730706],\n",
       "       [0.85528973, 0.14471027],\n",
       "       [0.88225767, 0.11774233],\n",
       "       [0.88838772, 0.11161228],\n",
       "       [0.20882912, 0.79117088],\n",
       "       [0.78290779, 0.21709221],\n",
       "       [0.3693535 , 0.6306465 ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터(타이타닉)의 분류 결정 예측 확률을 반환해준다.\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "\n",
    "pred_proba.shape\n",
    "pred_proba[:10]  # [Negatve(0)가 될 확률, Positive(1)가 될 확률]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터 predict 결과\n",
    "pred  = lr_clf.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 확률(pred_proba)과 예측 결과값(pred)을 결합해서 비교해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46175211, 0.53824789, 1.        ],\n",
       "       [0.87863924, 0.12136076, 0.        ],\n",
       "       [0.87717092, 0.12282908, 0.        ],\n",
       "       [0.88269294, 0.11730706, 0.        ],\n",
       "       [0.85528973, 0.14471027, 0.        ],\n",
       "       [0.88225767, 0.11774233, 0.        ],\n",
       "       [0.88838772, 0.11161228, 0.        ],\n",
       "       [0.20882912, 0.79117088, 1.        ],\n",
       "       [0.78290779, 0.21709221, 0.        ],\n",
       "       [0.3693535 , 0.6306465 , 1.        ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 결과값은 1차원 이므로 2차원으로 reshape 한 후에 예측 확률과 oncatenate 함\n",
    "pred_proba_result = np.concatenate([pred_proba , pred.reshape(-1, 1)],axis=1)\n",
    "\n",
    "# 두개의 class 중에서 더 큰 확률을 클래스 값으로 예측\n",
    "pred_proba_result[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizer : 요소들이 기준값보다 큰지 작은지를 알려주는 함수"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<Binarizer>\n",
    "요소가 기준값(threshold)과 비교해서,\n",
    "- 같거나 작으면 0을 반환\n",
    "- 크면 1을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[ 1, -1,  2],\n",
    "     [ 2,  0,  0],\n",
    "     [ 0,  1.1, 1.2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Binarizer의 threshold를 1.1로 세팅.\n",
    "binarizer = Binarizer(threshold=1.1)                     \n",
    "\n",
    "# array X의 값들이 1.1보다 작거나 같으면 0, 크면 1을 반환한다.\n",
    "binarizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 임계값 0.5로 예측값 변환(Binarizer 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53824789],\n",
       "       [0.12136076],\n",
       "       [0.12282908],\n",
       "       [0.11730706],\n",
       "       [0.14471027],\n",
       "       [0.11774233],\n",
       "       [0.11161228],\n",
       "       [0.79117088],\n",
       "       [0.21709221],\n",
       "       [0.6306465 ],\n",
       "       [0.10017236],\n",
       "       [0.12502264],\n",
       "       [0.12283511],\n",
       "       [0.11165858],\n",
       "       [0.56352896],\n",
       "       [0.14106496],\n",
       "       [0.09626215],\n",
       "       [0.26655139],\n",
       "       [0.27520975],\n",
       "       [0.82820508],\n",
       "       [0.24636982],\n",
       "       [0.38070654],\n",
       "       [0.14543006],\n",
       "       [0.18514805],\n",
       "       [0.11203246],\n",
       "       [0.23445307],\n",
       "       [0.14030802],\n",
       "       [0.07414516],\n",
       "       [0.28037989],\n",
       "       [0.30448184],\n",
       "       [0.94725314],\n",
       "       [0.81744533],\n",
       "       [0.12677781],\n",
       "       [0.82606966],\n",
       "       [0.39929127],\n",
       "       [0.23445307],\n",
       "       [0.07239623],\n",
       "       [0.61121278],\n",
       "       [0.05293635],\n",
       "       [0.10394781],\n",
       "       [0.35050439],\n",
       "       [0.08335452],\n",
       "       [0.82184592],\n",
       "       [0.70772506],\n",
       "       [0.63056078],\n",
       "       [0.6305772 ],\n",
       "       [0.91891158],\n",
       "       [0.35872277],\n",
       "       [0.94885769],\n",
       "       [0.11206729],\n",
       "       [0.59301267],\n",
       "       [0.11165858],\n",
       "       [0.13283413],\n",
       "       [0.72520926],\n",
       "       [0.30930873],\n",
       "       [0.19696528],\n",
       "       [0.22627228],\n",
       "       [0.12283013],\n",
       "       [0.15425586],\n",
       "       [0.43218691],\n",
       "       [0.28008564],\n",
       "       [0.10077886],\n",
       "       [0.54554871],\n",
       "       [0.51359943],\n",
       "       [0.44421615],\n",
       "       [0.09462614],\n",
       "       [0.66696692],\n",
       "       [0.59430053],\n",
       "       [0.95184001],\n",
       "       [0.14806889],\n",
       "       [0.12891671],\n",
       "       [0.16850646],\n",
       "       [0.10395007],\n",
       "       [0.9479995 ],\n",
       "       [0.19860132],\n",
       "       [0.11165858],\n",
       "       [0.34807784],\n",
       "       [0.18363793],\n",
       "       [0.83564399],\n",
       "       [0.12283013],\n",
       "       [0.79492515],\n",
       "       [0.6452204 ],\n",
       "       [0.93097705],\n",
       "       [0.13310088],\n",
       "       [0.94898036],\n",
       "       [0.95041784],\n",
       "       [0.15341146],\n",
       "       [0.12547606],\n",
       "       [0.87445816],\n",
       "       [0.11165858],\n",
       "       [0.11165858],\n",
       "       [0.23445307],\n",
       "       [0.232227  ],\n",
       "       [0.11165858],\n",
       "       [0.6305772 ],\n",
       "       [0.07573906],\n",
       "       [0.92883579],\n",
       "       [0.10074608],\n",
       "       [0.50559004],\n",
       "       [0.9650902 ],\n",
       "       [0.5017425 ],\n",
       "       [0.09451319],\n",
       "       [0.94803128],\n",
       "       [0.09757055],\n",
       "       [0.53011318],\n",
       "       [0.12841466],\n",
       "       [0.1411124 ],\n",
       "       [0.14806859],\n",
       "       [0.44943522],\n",
       "       [0.10773598],\n",
       "       [0.11701687],\n",
       "       [0.10892335],\n",
       "       [0.40328333],\n",
       "       [0.65378607],\n",
       "       [0.11203246],\n",
       "       [0.07102699],\n",
       "       [0.1243399 ],\n",
       "       [0.19836924],\n",
       "       [0.9259365 ],\n",
       "       [0.06868262],\n",
       "       [0.11164965],\n",
       "       [0.13068136],\n",
       "       [0.06363514],\n",
       "       [0.32179158],\n",
       "       [0.01160772],\n",
       "       [0.11164965],\n",
       "       [0.1162389 ],\n",
       "       [0.31660413],\n",
       "       [0.67782678],\n",
       "       [0.32155052],\n",
       "       [0.9650902 ],\n",
       "       [0.45377068],\n",
       "       [0.73525391],\n",
       "       [0.44256386],\n",
       "       [0.57004712],\n",
       "       [0.35074095],\n",
       "       [0.74840819],\n",
       "       [0.1862258 ],\n",
       "       [0.10397544],\n",
       "       [0.80333037],\n",
       "       [0.90889479],\n",
       "       [0.14806859],\n",
       "       [0.11803438],\n",
       "       [0.1012163 ],\n",
       "       [0.09165907],\n",
       "       [0.66771448],\n",
       "       [0.07569363],\n",
       "       [0.23361605],\n",
       "       [0.91817095],\n",
       "       [0.16814009],\n",
       "       [0.42847831],\n",
       "       [0.63158136],\n",
       "       [0.63679615],\n",
       "       [0.12277408],\n",
       "       [0.77776787],\n",
       "       [0.88094245],\n",
       "       [0.48750572],\n",
       "       [0.1329989 ],\n",
       "       [0.75156419],\n",
       "       [0.69054558],\n",
       "       [0.14982642],\n",
       "       [0.79288478],\n",
       "       [0.09129555],\n",
       "       [0.66689887],\n",
       "       [0.3803036 ],\n",
       "       [0.65147146],\n",
       "       [0.88414766],\n",
       "       [0.30892803],\n",
       "       [0.09167851],\n",
       "       [0.89305329],\n",
       "       [0.11161228],\n",
       "       [0.85429274],\n",
       "       [0.25042401],\n",
       "       [0.24013692],\n",
       "       [0.40073604],\n",
       "       [0.06232682],\n",
       "       [0.14111947],\n",
       "       [0.54497719],\n",
       "       [0.62683822]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# predict_proba 반환값의 두번째 컬럼, 즉 Positive 컬럼을 추출한 후\n",
    "# (1차원 이므로 2차원으로 reshape으로 해준다.)\n",
    "pred_proba_1 = pred_proba[:, 1].reshape(-1, 1)\n",
    "pred_proba_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Binarizer(threshold=0.5)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Binarizer(threshold=0.5)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binarizer를 적용 - threshold는 0.5로 세팅(0.5 : 분류 결정 임계값)\n",
    "custom_threshold = 0.5\n",
    "binarizer = Binarizer(threshold=custom_threshold)\n",
    "binarizer.fit(pred_proba_1)\n",
    "binarizer.transform(pred_proba_1)\n",
    "binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Positive 컬럼에 Binarizer를 적용하면 1 or 0을 예측한다.\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "# 예측 결과와 실제 값 간의 오차행렬을 구해보면\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> 3.2의 결과(정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869)와 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이번에는 분류 임계값을 0.4로 낮춰서 예측값을 보면 재현율이 높아지는지 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[98 20]\n",
      " [10 51]]\n",
      "정확도: 0.8324, 정밀도: 0.7183, 재현율: 0.8361 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binarizer의 threshold 설정값을 0.4로 설정. 즉 분류 결정 임곗값을 0.5에서 0.4로 낮춤  \n",
    "custom_threshold = 0.4\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test , custom_predict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> 분류 결정 임계값이 낮아지니 재현율이 높아졌다(0.7869 -> 0.8361)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 임곗값을 증가시키면서 예측값 변환(Binarizer 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임곗값: 0.4\n",
      "오차 행렬\n",
      "[[98 20]\n",
      " [10 51]]\n",
      "정확도: 0.8324, 정밀도: 0.7183, 재현율: 0.8361 \n",
      "\n",
      "임곗값: 0.45\n",
      "오차 행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도: 0.8492, 정밀도: 0.7656, 재현율: 0.8033 \n",
      "\n",
      "임곗값: 0.5\n",
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869 \n",
      "\n",
      "임곗값: 0.55\n",
      "오차 행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도: 0.8659, 정밀도: 0.8364, 재현율: 0.7541 \n",
      "\n",
      "임곗값: 0.6\n",
      "오차 행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도: 0.8771, 정밀도: 0.8824, 재현율: 0.7377 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 임곗값(threshold)을 점차 높여보면 재현율이 감소할까?\n",
    "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
    "\n",
    "def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n",
    "    # 임계값을 차례로 돌면서 Evaluation 수행.\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        \n",
    "        # 임계값에 따른 결과들이 출력된다.\n",
    "        print('임곗값:', custom_threshold)\n",
    "        get_clf_eval(y_test , custom_predict)\n",
    "\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> 분류 임계값을 점차 높이니 재현율은 점차 감소하고, 정밀도는 점차 증가한다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "결론 :\n",
    "적절한 분류 임계값을 설정하면 원하는 정밀도, 재현율 각각의 값을 구할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## precision_recall_curve( ) 를 이용하여 임곗값에 따른 정밀도-재현율 값 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53824789, 0.12136076, 0.12282908, 0.11730706, 0.14471027,\n",
       "       0.11774233, 0.11161228, 0.79117088, 0.21709221, 0.6306465 ,\n",
       "       0.10017236, 0.12502264, 0.12283511, 0.11165858, 0.56352896,\n",
       "       0.14106496, 0.09626215, 0.26655139, 0.27520975, 0.82820508,\n",
       "       0.24636982, 0.38070654, 0.14543006, 0.18514805, 0.11203246,\n",
       "       0.23445307, 0.14030802, 0.07414516, 0.28037989, 0.30448184,\n",
       "       0.94725314, 0.81744533, 0.12677781, 0.82606966, 0.39929127,\n",
       "       0.23445307, 0.07239623, 0.61121278, 0.05293635, 0.10394781,\n",
       "       0.35050439, 0.08335452, 0.82184592, 0.70772506, 0.63056078,\n",
       "       0.6305772 , 0.91891158, 0.35872277, 0.94885769, 0.11206729,\n",
       "       0.59301267, 0.11165858, 0.13283413, 0.72520926, 0.30930873,\n",
       "       0.19696528, 0.22627228, 0.12283013, 0.15425586, 0.43218691,\n",
       "       0.28008564, 0.10077886, 0.54554871, 0.51359943, 0.44421615,\n",
       "       0.09462614, 0.66696692, 0.59430053, 0.95184001, 0.14806889,\n",
       "       0.12891671, 0.16850646, 0.10395007, 0.9479995 , 0.19860132,\n",
       "       0.11165858, 0.34807784, 0.18363793, 0.83564399, 0.12283013,\n",
       "       0.79492515, 0.6452204 , 0.93097705, 0.13310088, 0.94898036,\n",
       "       0.95041784, 0.15341146, 0.12547606, 0.87445816, 0.11165858,\n",
       "       0.11165858, 0.23445307, 0.232227  , 0.11165858, 0.6305772 ,\n",
       "       0.07573906, 0.92883579, 0.10074608, 0.50559004, 0.9650902 ,\n",
       "       0.5017425 , 0.09451319, 0.94803128, 0.09757055, 0.53011318,\n",
       "       0.12841466, 0.1411124 , 0.14806859, 0.44943522, 0.10773598,\n",
       "       0.11701687, 0.10892335, 0.40328333, 0.65378607, 0.11203246,\n",
       "       0.07102699, 0.1243399 , 0.19836924, 0.9259365 , 0.06868262,\n",
       "       0.11164965, 0.13068136, 0.06363514, 0.32179158, 0.01160772,\n",
       "       0.11164965, 0.1162389 , 0.31660413, 0.67782678, 0.32155052,\n",
       "       0.9650902 , 0.45377068, 0.73525391, 0.44256386, 0.57004712,\n",
       "       0.35074095, 0.74840819, 0.1862258 , 0.10397544, 0.80333037,\n",
       "       0.90889479, 0.14806859, 0.11803438, 0.1012163 , 0.09165907,\n",
       "       0.66771448, 0.07569363, 0.23361605, 0.91817095, 0.16814009,\n",
       "       0.42847831, 0.63158136, 0.63679615, 0.12277408, 0.77776787,\n",
       "       0.88094245, 0.48750572, 0.1329989 , 0.75156419, 0.69054558,\n",
       "       0.14982642, 0.79288478, 0.09129555, 0.66689887, 0.3803036 ,\n",
       "       0.65147146, 0.88414766, 0.30892803, 0.09167851, 0.89305329,\n",
       "       0.11161228, 0.85429274, 0.25042401, 0.24013692, 0.40073604,\n",
       "       0.06232682, 0.14111947, 0.54497719, 0.62683822])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측값 Positive(1)일 확률 \n",
    "lr_clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.53824789, 0.12136076, 0.12282908, 0.11730706, 0.14471027,\n",
       "       0.11774233, 0.11161228, 0.79117088, 0.21709221, 0.6306465 ,\n",
       "       0.10017236, 0.12502264, 0.12283511, 0.11165858, 0.56352896,\n",
       "       0.14106496, 0.09626215, 0.26655139, 0.27520975, 0.82820508,\n",
       "       0.24636982, 0.38070654, 0.14543006, 0.18514805, 0.11203246,\n",
       "       0.23445307, 0.14030802, 0.07414516, 0.28037989, 0.30448184,\n",
       "       0.94725314, 0.81744533, 0.12677781, 0.82606966, 0.39929127,\n",
       "       0.23445307, 0.07239623, 0.61121278, 0.05293635, 0.10394781,\n",
       "       0.35050439, 0.08335452, 0.82184592, 0.70772506, 0.63056078,\n",
       "       0.6305772 , 0.91891158, 0.35872277, 0.94885769, 0.11206729,\n",
       "       0.59301267, 0.11165858, 0.13283413, 0.72520926, 0.30930873,\n",
       "       0.19696528, 0.22627228, 0.12283013, 0.15425586, 0.43218691,\n",
       "       0.28008564, 0.10077886, 0.54554871, 0.51359943, 0.44421615,\n",
       "       0.09462614, 0.66696692, 0.59430053, 0.95184001, 0.14806889,\n",
       "       0.12891671, 0.16850646, 0.10395007, 0.9479995 , 0.19860132,\n",
       "       0.11165858, 0.34807784, 0.18363793, 0.83564399, 0.12283013,\n",
       "       0.79492515, 0.6452204 , 0.93097705, 0.13310088, 0.94898036,\n",
       "       0.95041784, 0.15341146, 0.12547606, 0.87445816, 0.11165858,\n",
       "       0.11165858, 0.23445307, 0.232227  , 0.11165858, 0.6305772 ,\n",
       "       0.07573906, 0.92883579, 0.10074608, 0.50559004, 0.9650902 ,\n",
       "       0.5017425 , 0.09451319, 0.94803128, 0.09757055, 0.53011318,\n",
       "       0.12841466, 0.1411124 , 0.14806859, 0.44943522, 0.10773598,\n",
       "       0.11701687, 0.10892335, 0.40328333, 0.65378607, 0.11203246,\n",
       "       0.07102699, 0.1243399 , 0.19836924, 0.9259365 , 0.06868262,\n",
       "       0.11164965, 0.13068136, 0.06363514, 0.32179158, 0.01160772,\n",
       "       0.11164965, 0.1162389 , 0.31660413, 0.67782678, 0.32155052,\n",
       "       0.9650902 , 0.45377068, 0.73525391, 0.44256386, 0.57004712,\n",
       "       0.35074095, 0.74840819, 0.1862258 , 0.10397544, 0.80333037,\n",
       "       0.90889479, 0.14806859, 0.11803438, 0.1012163 , 0.09165907,\n",
       "       0.66771448, 0.07569363, 0.23361605, 0.91817095, 0.16814009,\n",
       "       0.42847831, 0.63158136, 0.63679615, 0.12277408, 0.77776787,\n",
       "       0.88094245, 0.48750572, 0.1329989 , 0.75156419, 0.69054558,\n",
       "       0.14982642, 0.79288478, 0.09129555, 0.66689887, 0.3803036 ,\n",
       "       0.65147146, 0.88414766, 0.30892803, 0.09167851, 0.89305329,\n",
       "       0.11161228, 0.85429274, 0.25042401, 0.24013692, 0.40073604,\n",
       "       0.06232682, 0.14111947, 0.54497719, 0.62683822])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# 레이블 값이 1일 예측 확률들을 추출\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(pred_proba_class1.shape)\n",
    "pred_proba_class1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류 임곗값 Shape  : (143,) \n",
      "\n",
      "precisions Shape: (144,)\n",
      "recalls Shape   : (144,)\n"
     ]
    }
   ],
   "source": [
    "# 실제값과 예측 확률(레이블 값이 1일 때)을 precision_recall_curve 인자로 입력\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1)\n",
    "print('분류 임곗값 Shape  :', thresholds.shape, '\\n')\n",
    "\n",
    "print('precisions Shape:', precisions.shape)\n",
    "print('recalls Shape   :', recalls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresholds 5 sample: [0.10394781 0.10395007 0.10397544 0.10773598 0.10892335] \n",
      "\n",
      "precisions 5 sample: [0.38853503 0.38461538 0.38709677 0.38961039 0.38562092]\n",
      "recalls 5 sample:    [1.         0.98360656 0.98360656 0.98360656 0.96721311]\n"
     ]
    }
   ],
   "source": [
    "print(\"thresholds 5 sample:\", thresholds[:5], '\\n')\n",
    "\n",
    "print(\"precisions 5 sample:\", precisions[:5])\n",
    "print(\"recalls 5 sample:   \", recalls[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  15,  30,  45,  60,  75,  90, 105, 120, 135])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 143, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임계값 배열 index 10개: [  0  15  30  45  60  75  90 105 120 135]\n",
      "샘플용 10개의 임곗값:  [0.1  0.12 0.14 0.19 0.28 0.4  0.56 0.67 0.82 0.95]\n"
     ]
    }
   ],
   "source": [
    "# 반환된 임계값 배열 로우가 143건이므로 샘플로 10건만 추출하되, 임곗값을 15개씩 건너 뛰며 추출. \n",
    "thr_index = np.arange(0, thresholds.shape[0], 15)\n",
    "print('임계값 배열 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플용 10개의 임곗값:  [0.1  0.12 0.14 0.19 0.28 0.4  0.56 0.67 0.82 0.95] \n",
      "\n",
      "샘플 임계값 별 정밀도:  [0.389 0.44  0.466 0.539 0.647 0.729 0.836 0.949 0.958 1.   ]\n",
      "샘플 임계값 별 재현율:  [1.    0.967 0.902 0.902 0.902 0.836 0.754 0.607 0.377 0.148]\n"
     ]
    }
   ],
   "source": [
    "# 15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값 \n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2), '\\n')\n",
    "\n",
    "print('샘플 임계값 별 정밀도: ', np.round(precisions[thr_index], 3))\n",
    "print('샘플 임계값 별 재현율: ', np.round(recalls[thr_index], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임곗값의 변경에 따른 정밀도-재현율 변화 곡선을 그림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "# 정밀도, 재현율 변화 그래프 그리는 코드\n",
    "def precision_recall_curve_plot(y_test , pred_proba_c1):\n",
    "    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. \n",
    "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
    "    \n",
    "    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n",
    "    plt.title('Precision and recall by classification threshold')\n",
    "    \n",
    "    # threshold 값 X 축의 Scale을 0.1 단위로 변경\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
    "    \n",
    "    # x축, y축 label과 legend, 그리고 grid 설정\n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# 분류 임계값이 변화됨에 따라 정밀도(precision), 재현율(recall) 추이\n",
    "precision_recall_curve_plot( y_test, lr_clf.predict_proba(X_test)[:, 1] )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> 분류 임계값이 증가하면 재현율(recall)이 감소하고, 정밀도(precision)가 증가한다.\n",
    "-> 분류 임계값이 감소하면 재현율(recall)이 증가하고, 정밀도(precision)가 감소한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 스코어: 0.7805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score \n",
    "\n",
    "# f1_score 클래스를 이용해서 f1 score 계산\n",
    "f1 = f1_score(y_test, pred) # 실제값, 예측값\n",
    "print('F1 스코어: {0:.4f}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임곗값: 0.4\n",
      "오차 행렬\n",
      "[[98 20]\n",
      " [10 51]]\n",
      "정확도: 0.8324, 정밀도: 0.7183, 재현율: 0.8361, F1:0.7727 \n",
      "\n",
      "임곗값: 0.45\n",
      "오차 행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도: 0.8492, 정밀도: 0.7656, 재현율: 0.8033, F1:0.7840 \n",
      "\n",
      "임곗값: 0.5\n",
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869, F1:0.7805 \n",
      "\n",
      "임곗값: 0.55\n",
      "오차 행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도: 0.8659, 정밀도: 0.8364, 재현율: 0.7541, F1:0.7931 \n",
      "\n",
      "임곗값: 0.6\n",
      "오차 행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도: 0.8771, 정밀도: 0.8824, 재현율: 0.7377, F1:0.8036 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    \n",
    "    # F1 스코어 추가\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # f1 score print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1), '\\n')\n",
    "\n",
    "thresholds = [0.4 , 0.45 , 0.50 , 0.55 , 0.60]\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "\n",
    "# 분류 임계값 변경을 하면서 f1 score를 포함한 평가지표 확인\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> 임계값이 0.6일 때 f1 score가 가장 높다.\n",
    "그런데 재현율이 너무 낮기 때문에 여러가지 요소를 고려해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-5 ROC Curve와 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.53824789, 0.12136076, 0.12282908, 0.11730706, 0.14471027,\n",
       "       0.11774233, 0.11161228, 0.79117088, 0.21709221, 0.6306465 ,\n",
       "       0.10017236, 0.12502264, 0.12283511, 0.11165858, 0.56352896,\n",
       "       0.14106496, 0.09626215, 0.26655139, 0.27520975, 0.82820508])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
    "\n",
    "print(len(pred_proba_class1))\n",
    "pred_proba_class1[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류 임곗값 Shape : (55,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fpr, tps, thresholds\n",
    "fprs , tprs , thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "\n",
    "print('분류 임곗값 Shape :', thresholds.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 추출을 위한 임곗값 배열의 index 10개: [ 0  5 10 15 20 25 30 35 40 45 50]\n",
      "샘플용 10개의 임곗값:  [1.97 0.75 0.63 0.59 0.49 0.4  0.35 0.23 0.13 0.12 0.11]\n"
     ]
    }
   ],
   "source": [
    "# 반환된 임곗값 배열 로우가 55건이므로 샘플로 10건만 추출하되, 임곗값을 5 Step으로 추출. \n",
    "thr_index = np.arange(0, thresholds.shape[0], 5)\n",
    "print('샘플 추출을 위한 임곗값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 임곗값별 FPR:  [0.    0.017 0.034 0.051 0.127 0.161 0.203 0.331 0.585 0.636 0.797]\n",
      "샘플 임곗값별 TPR:  [0.    0.475 0.689 0.754 0.787 0.836 0.869 0.902 0.918 0.967 0.967]\n"
     ]
    }
   ],
   "source": [
    "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
    "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
    "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def roc_curve_plot(y_test , pred_proba_c1):\n",
    "    # 임곗값에 따른 FPR, TPR 값을 반환 받음. \n",
    "    fprs , tprs , thresholds = roc_curve(y_test ,pred_proba_c1)\n",
    "\n",
    "    # ROC Curve를 plot 곡선으로 그림. \n",
    "    plt.plot(fprs , tprs, label='ROC')\n",
    "    \n",
    "    # 가운데 대각선 직선(random 값일 때)을 그림. \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    \n",
    "    # FPR X 축의 Scale을 0.1 단위로 변경, X,Y 축명 설정등   \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    plt.xlim(0,1); plt.ylim(0,1)\n",
    "    plt.xlabel('FPR( 1 - Sensitivity )'); plt.ylabel('TPR( Recall )')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 값: 0.9024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "### 아래는 roc_auc_score()의 인자를 잘못 입력한 것으로, 책에서 수정이 필요한 부분입니다. \n",
    "### 책에서는 roc_auc_score(y_test, pred)로 예측 타겟값을 입력하였으나 \n",
    "### roc_auc_score(y_test, y_score)로 y_score는 predict_proba()로 호출된 예측 확률 ndarray중 Positive 열에 해당하는 ndarray입니다. \n",
    "\n",
    "# pred = lr_clf.predict(X_test)\n",
    "# roc_score = roc_auc_score(y_test, pred)\n",
    "\n",
    "# 수정된 내용\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "roc_score = roc_auc_score(y_test, pred_proba)\n",
    "print('ROC AUC 값: {0:.4f}'.format(roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC가 추가된 get_clf_eval 함수 \n",
    "# : 모델의 평가지표들(오차 행렬, 정확도, 정밀도, 재현율, f1 score, ROC AUC)을 보여준다.\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    \n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "          F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
